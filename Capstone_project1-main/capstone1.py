# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-glOw5zzrhNJH7b9US6Q0oZRiSz8o48X
"""

import pandas as pd

df = pd.read_csv('manufacturing_dataset_1000_samples.csv')

print(df.head())

"""## Data understanding

### Subtask:
Inspect the dataset by checking datatypes, summary statistics, and distributions.

"""

df.info()
print(df.describe())
print(df.describe(include='object'))

"""## Preprocessing

### Subtask:
timestamp- Convert the 'Timestamp' column to datetime objects and extract relevant time-based features. Then, check the head of the dataframe to verify the changes.

"""

df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%d-%m-%Y %H:%M')
df['Hour'] = df['Timestamp'].dt.hour
df['Day_of_Week_Num'] = df['Timestamp'].dt.dayofweek
df['Month'] = df['Timestamp'].dt.month

print(df.head())

"""**Subtask**
The 'Timestamp' column has been successfully converted to datetime objects and relevant time-based features have been extracted. Since the extracted features capture the temporal information needed for the analysis, the original 'Timestamp' column is no longer necessary and can be dropped to avoid redundancy.


"""

df = df.drop('Timestamp', axis=1)
print(df.head())

"""## Preprocessing - missing values

### Subtask:
Handle missing values using an appropriate strategy (mean, median, or mode).

"""

print(df.isnull().sum())

# Impute missing values in 'Material_Viscosity' with the mean
df['Material_Viscosity'].fillna(df['Material_Viscosity'].mean(), inplace=True)

# Impute missing values in 'Ambient_Temperature' with the mean
df['Ambient_Temperature'].fillna(df['Ambient_Temperature'].mean(), inplace=True)

# Impute missing values in 'Operator_Experience' with the mean
df['Operator_Experience'].fillna(df['Operator_Experience'].mean(), inplace=True)

# Verify that there are no remaining missing values
print(df.isnull().sum())

"""## Preprocessing - categorical encoding

### Subtask:
Encode the categorical variables (Shift, Machine_Type, Material_Grade, Day_of_Week).
Apply one-hot encoding to the specified categorical columns
"""

categorical_cols = ['Shift', 'Machine_Type', 'Material_Grade', 'Day_of_Week']
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

print(df_encoded.head())

"""## Preprocessing - numerical scaling

### Subtask:
Scale the numerical features using a suitable scaler (StandardScaler or MinMaxScaler).

"""

from sklearn.preprocessing import StandardScaler

numerical_cols = df_encoded.select_dtypes(include=['float64', 'int64']).columns.tolist()
numerical_cols.remove('Parts_Per_Hour')

scaler = StandardScaler()

df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])

print(df_encoded.head())

"""## Exploratory data analysis (eda)

### Subtask:
Perform univariate and bivariate analysis, identify outliers, and visualize feature importance.

"""

import matplotlib.pyplot as plt
import seaborn as sns

numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()
categorical_cols = ['Shift', 'Machine_Type', 'Material_Grade', 'Day_of_Week']

# Histograms for numerical features
df[numerical_cols].hist(figsize=(15, 10))
plt.tight_layout()
plt.show()

# Box plots for numerical features to identify outliers
plt.figure(figsize=(15, 10))
sns.boxplot(data=df[numerical_cols])
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

# Scatter plots against 'Parts_Per_Hour'
fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20, 15))
axes = axes.flatten()
for i, col in enumerate(numerical_cols):
    if col != 'Parts_Per_Hour':
        sns.scatterplot(x=df[col], y=df['Parts_Per_Hour'], ax=axes[i])
        axes[i].set_title(f'{col} vs Parts_Per_Hour')
fig.delaxes(axes[len(numerical_cols)-1]) # Remove the empty subplot for 'Parts_Per_Hour' vs 'Parts_Per_Hour'
plt.tight_layout()
plt.show()


# Correlation matrix and heatmap
correlation_matrix = df[numerical_cols].corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Numerical Features')
plt.show()

# Box plots for categorical features vs 'Parts_Per_Hour'
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))
axes = axes.flatten()
for i, col in enumerate(categorical_cols):
    sns.boxplot(x=df[col], y=df['Parts_Per_Hour'], ax=axes[i])
    axes[i].set_title(f'{col} vs Parts_Per_Hour')
plt.tight_layout()
plt.show()

"""## Modeling

### Subtask:
Split the data into training and testing sets and build a Linear Regression model
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

X = df_encoded.drop('Parts_Per_Hour', axis=1)
y = df_encoded['Parts_Per_Hour']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

"""## Evaluation

### Subtask:
Evaluate the model using regression metrics (RMSE, MSE, R²).

"""

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error (MSE): {mse:.2f}')
print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')
print(f'R-squared (R²): {r2:.2f}')

"""## Summarize results

### Subtask:
Summarize insights and errors from the model evaluation.

"""

print("Model Evaluation Summary:")
print("--------------------------")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R-squared (R²): {r2:.2f}")
print("\nInterpretation:")
print(f"- MSE ({mse:.2f}): This is the average of the squared errors. It gives a measure of the average magnitude of the errors. A lower MSE indicates a better fit to the data. The value of {mse:.2f} represents the average squared difference between the predicted and actual 'Parts_Per_Hour' values.")
print(f"- RMSE ({rmse:.2f}): This is the square root of the MSE. It provides an error metric in the same units as the target variable ('Parts_Per_Hour'). An RMSE of {rmse:.2f} means, on average, the model's predictions are off by about {rmse:.2f} parts per hour.")
print(f"- R-squared (R²) ({r2:.2f}): This metric represents the proportion of the variance in the dependent variable ('Parts_Per_Hour') that is predictable from the independent variables. An R² of {r2:.2f} indicates that approximately {r2*100:.2f}% of the variability in 'Parts_Per_Hour' can be explained by the model. A value close to 1 suggests a good fit.")

print("\nInitial Thoughts on Improvement:")
print("The R-squared value of {r2:.2f} suggests that the model explains a high proportion of the variance in 'Parts_Per_Hour', indicating a reasonably good fit. The RMSE of {rmse:.2f} provides a sense of the typical prediction error. While the current performance is good, potential areas for improvement could include exploring non-linear models, feature engineering, or investigating potential outliers that might be influencing the errors.")

"""## Deployment

### Subtask:
Set up a FastAPI endpoint

"""

import joblib

# Assuming you already have a trained model and scaler
# Example:
# model = LinearRegression().fit(X_train, y_train)
# scaler = StandardScaler().fit(X_train)

# Save the trained model
joblib.dump(model, 'linear_regression_model.pkl')

# Save the scaler
joblib.dump(scaler, 'scaler.pkl')

training_columns = X_train.columns
joblib.dump(X_train.columns, 'model_columns.pkl')
joblib.dump(rmse, 'rmse.pkl')

print("Model, scaler, model_columns.pkl and rmse.pkl saved successfully!")